{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import my_functions as mf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pycaret.regression import *\n",
    "# from pycaret.time_series import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Y training data for A:\n",
    "Y_train_a = pd.read_parquet('data/A/train_targets.parquet')\n",
    "\n",
    "# Loading X training data for A:\n",
    "X_train_a = pd.concat([pd.read_parquet('data/A/X_train_observed.parquet'), pd.read_parquet('data/A/X_train_estimated.parquet').drop(\"date_calc\", axis=1)])\n",
    "\n",
    "# Loading X test data for A:\n",
    "X_test_a = pd.read_parquet('data/A/X_test_estimated.parquet').drop(\"date_calc\", axis=1)\n",
    "\n",
    "Y_train_a_clean, X_train_a_clean, X_test_a_clean, X_a_clean, train_a_clean = mf.full_clean(Y_train_a,X_train_a,X_test_a)\n",
    "# Y_train_a_clean_hourly, X_train_a_clean_hourly, X_test_a_clean_hourly, X_a_clean_hourly = full_clean(Y_train_a,X_train_a,X_test_a,False)\n",
    "\n",
    "# Loading Y training data for B:\n",
    "Y_train_b = pd.read_parquet('data/B/train_targets.parquet')\n",
    "\n",
    "# Loading X training data for B:\n",
    "X_train_b = pd.concat([pd.read_parquet('data/B/X_train_observed.parquet'), pd.read_parquet('data/B/X_train_estimated.parquet').drop(\"date_calc\", axis=1)])\n",
    "\n",
    "# Loading X test data for B:\n",
    "X_test_b = pd.read_parquet('data/B/X_test_estimated.parquet').drop(\"date_calc\", axis=1)\n",
    "\n",
    "Y_train_b_clean, X_train_b_clean, X_test_b_clean, X_b_clean, train_b_clean = mf.full_clean(Y_train_b,X_train_b,X_test_b)\n",
    "# Y_train_b_clean_hourly, X_train_b_clean_hourly, X_test_b_clean_hourly, X_b_clean_hourly = full_clean(Y_train_b,X_train_b,X_test_b,False)\n",
    "\n",
    "# Loading Y training data for C:\n",
    "Y_train_c = pd.read_parquet('data/C/train_targets.parquet')\n",
    "\n",
    "# Loading X training data for C:\n",
    "X_train_c = pd.concat([pd.read_parquet('data/C/X_train_observed.parquet'), pd.read_parquet('data/C/X_train_estimated.parquet').drop(\"date_calc\", axis=1)])\n",
    "\n",
    "# Loading X test data for C:\n",
    "X_test_c = pd.read_parquet('data/C/X_test_estimated.parquet').drop(\"date_calc\", axis=1)\n",
    "\n",
    "Y_train_c_clean, X_train_c_clean, X_test_c_clean, X_c_clean, train_c_clean = mf.full_clean(Y_train_c,X_train_c,X_test_c)\n",
    "# Y_train_c_clean_hourly, X_train_c_clean_hourly, X_test_c_clean_hourly, X_c_clean_hourly = full_clean(Y_train_c,X_train_c,X_test_c,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main stuff:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_a = setup(train_a_clean, target = \"pv_measurement\", train_size = 0.975, categorical_features = [\"dew_or_rime__idx\", \"elevation__m\", \"is_day__idx\", \"is_in_shadow__idx\", \"precip_type_5min__idx\", \"snow_drift__idx\", \"wind_speed_w_1000hPa__ms\"], session_id = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_a = setup_a.compare_models(sort = \"MAE\", fold = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_best_a = tune_model(best_a, optimize = \"MAE\", fold = 5, n_iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(best_a)\n",
    "# tuned_best_a = tune_model(best_a, optimize = \"MAE\", fold = 10, n_iter = 100)\n",
    "# pred_holdout = predict_model(best_a)\n",
    "# predictions = predict_model(besta, data=X_test_a_clean)\n",
    "# predictions.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup_a.create_model(\"et\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_a = compare_models(fold = 20, sort = \"MAE\", exclude = [\"lar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(besta)\n",
    "# pred_holdout = predict_model(besta)\n",
    "# predictions = predict_model(besta, data=X_test_a_clean)\n",
    "# predictions.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_a = create_model(\"et\")\n",
    "# tuned_et_a = tune_model(et_a)\n",
    "final_et_a = finalize_model(et_a)\n",
    "pred_et_a_holdout = predict_model(final_et_a)\n",
    "predictions_et_a = predict_model(final_et_a, data = X_test_a_clean).iloc[:,-1:]\n",
    "predictions_et_a[predictions_et_a < 0 ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_a = create_model(\"lightgbm\")\n",
    "tuned_lightgbm_a = tune_model(lightgbm_a)\n",
    "final_lightgbm_a = finalize_model(tuned_lightgbm_a)\n",
    "pred_lightgbm_a_holdout = predict_model(final_lightgbm_a)\n",
    "predictions_lightgbm_a = predict_model(final_lightgbm_a, data = X_test_a_clean).iloc[:,-1:]\n",
    "predictions_lightgbm_a[predictions_lightgbm_a < 0 ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_a = setup_a.create_model(\"catboost\")\n",
    "tuned_cat_a = tune_model(cat_a, optimize = \"MAE\", fold = 10, n_iter = 100)\n",
    "final_cat_a = finalize_model(tuned_cat_a)\n",
    "pred_cat_a_holdout = predict_model(final_cat_a)\n",
    "predictions_cat_a = predict_model(final_cat_a, data = X_test_a_clean).iloc[:,-1:]\n",
    "predictions_cat_a[predictions_cat_a < 0 ] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_b = setup(train_b_clean, target = \"pv_measurement\", train_size = 0.975, categorical_features = [\"dew_or_rime__idx\", \"elevation__m\", \"is_day__idx\", \"is_in_shadow__idx\", \"precip_type_5min__idx\", \"snow_drift__idx\", \"wind_speed_w_1000hPa__ms\"], session_id = 0)\n",
    "# best_b = compare_models(fold = 20, sort = \"MAE\", exclude = [\"lar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_b = create_model(\"et\")\n",
    "# tuned_et_b = tune_model(et_b)\n",
    "final_et_b = finalize_model(et_b)\n",
    "pred_et_b_holdout = predict_model(final_et_b)\n",
    "predictions_et_b = predict_model(final_et_b, data = X_test_b_clean).iloc[:,-1:]\n",
    "predictions_et_b[predictions_et_b < 0 ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_b = create_model(\"lightgbm\")\n",
    "tuned_lightgbm_b = tune_model(lightgbm_b)\n",
    "final_lightgbm_b = finalize_model(tuned_lightgbm_b)\n",
    "pred_lightgbm_b_holdout = predict_model(final_lightgbm_b)\n",
    "predictions_lightgbm_b = predict_model(final_lightgbm_b, data = X_test_b_clean).iloc[:,-1:]\n",
    "predictions_lightgbm_b[predictions_lightgbm_b < 0 ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_b = setup_b.create_model(\"catboost\")\n",
    "tuned_cat_b = tune_model(cat_b, optimize = \"MAE\", fold = 10, n_iter = 100)\n",
    "final_cat_b = finalize_model(tuned_cat_b)\n",
    "pred_cat_b_holdout = predict_model(final_cat_b)\n",
    "predictions_cat_b = predict_model(final_cat_b, data = X_test_b_clean).iloc[:,-1:]\n",
    "predictions_cat_b[predictions_cat_b < 0 ] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_c = setup(train_c_clean, target = \"pv_measurement\", train_size = 0.97, categorical_features = [\"dew_or_rime__idx\", \"elevation__m\", \"is_day__idx\", \"is_in_shadow__idx\", \"precip_type_5min__idx\", \"snow_drift__idx\", \"wind_speed_w_1000hPa__ms\"], session_id = 0)\n",
    "# best_c = compare_models(fold = 20, sort = \"MAE\", exclude = [\"lar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_c = create_model(\"et\")\n",
    "tuned_et_c = tune_model(et_c)\n",
    "final_et_c = finalize_model(et_c)\n",
    "# pred_et_c_holdout = predict_model(final_et_c)\n",
    "predictions_et_c = predict_model(final_et_c, data = X_test_c_clean).iloc[:,-1:]\n",
    "predictions_et_c[predictions_et_c < 0 ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_c = create_model(\"lightgbm\")\n",
    "tuned_lightgbm_c = tune_model(lightgbm_c)\n",
    "final_lightgbm_c = finalize_model(tuned_lightgbm_c)\n",
    "pred_lightgbm_c_holdout = predict_model(final_lightgbm_c)\n",
    "predictions_lightgbm_c = predict_model(final_lightgbm_c, data = X_test_c_clean).iloc[:,-1:]\n",
    "predictions_lightgbm_c[predictions_lightgbm_c < 0 ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_c = setup_c.create_model(\"catboost\")\n",
    "tuned_cat_c = tune_model(cat_c, optimize = \"MAE\", fold = 10, n_iter = 100)\n",
    "final_cat_c = finalize_model(tuned_cat_c)\n",
    "pred_cat_c_holdout = predict_model(final_cat_c)\n",
    "predictions_cat_c = predict_model(final_cat_c, data = X_test_c_clean).iloc[:,-1:]\n",
    "predictions_cat_c[predictions_cat_c < 0 ] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.export_csv(np.concatenate([predictions_cat_a, predictions_cat_b, predictions_cat_c]), \"PyCaret_Tuned_10fold_100it_CatBoost\")\n",
    "# mf.export_csv(np.concatenate([predictions_lightgbm_a, predictions_lightgbm_b, predictions_lightgbm_c]), \"PyCaret_Tuned_LightGBM\")\n",
    "# mf.export_csv(np.concatenate([predictions_et_a, predictions_et_b, predictions_et_c]), \"PyCaret_Extra_Trees\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
